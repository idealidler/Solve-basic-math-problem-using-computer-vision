{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    train_data=[]\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename),cv2.IMREAD_GRAYSCALE)\n",
    "        img=~img #invert the image\n",
    "        if img is not None:\n",
    "            ret,thresh=cv2.threshold(img,127,255,cv2.THRESH_BINARY) #2nd argument is threshold value, 3rd is value to giv \n",
    "            \n",
    "            ctrs,hierarchy=cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnt=sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0]) #Bounding rectangle is the smallest \n",
    "                                                                      #horizontal rectangle enclosing the entire contour\n",
    "            w=int(28)\n",
    "            h=int(28)\n",
    "            maxi=0\n",
    "            for c in cnt:\n",
    "                x,y,w,h=cv2.boundingRect(c)   #(x,y) be the top-left coordin of the rectangle(w,h) be its width and height.\n",
    "                maxi=max(w*h,maxi)\n",
    "                if maxi==w*h:\n",
    "                    x_max=x\n",
    "                    y_max=y\n",
    "                    w_max=w\n",
    "                    h_max=h\n",
    "            im_crop= thresh[y_max:y_max+h_max+10, x_max:x_max+w_max+10]\n",
    "            im_resize = cv2.resize(im_crop,(28,28))\n",
    "            im_resize=np.reshape(im_resize,(784,1))\n",
    "            train_data.append(im_resize)\n",
    "    return train_data\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4152\n"
     ]
    }
   ],
   "source": [
    "data=load_images_from_folder('-')\n",
    "len(data)\n",
    "for i in range(0,len(data)):\n",
    "    data[i]=np.append(data[i],['10'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16320\n"
     ]
    }
   ],
   "source": [
    "data1=load_images_from_folder('1')\n",
    "\n",
    "for i in range(0,len(data1)):\n",
    "    data1[i]=np.append(data1[i],['1'])\n",
    "data=np.concatenate((data,data1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20580\n"
     ]
    }
   ],
   "source": [
    "data2=load_images_from_folder('2')\n",
    "\n",
    "for i in range(0,len(data2)):\n",
    "    data2[i]=np.append(data2[i],['2'])\n",
    "data=np.concatenate((data,data2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24096\n"
     ]
    }
   ],
   "source": [
    "data3=load_images_from_folder('3')\n",
    "\n",
    "for i in range(0,len(data3)):\n",
    "    data3[i]=np.append(data3[i],['3'])\n",
    "data=np.concatenate((data,data3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28128\n"
     ]
    }
   ],
   "source": [
    "data4=load_images_from_folder('4')\n",
    "\n",
    "for i in range(0,len(data4)):\n",
    "    data4[i]=np.append(data4[i],['4'])\n",
    "data=np.concatenate((data,data4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31672\n"
     ]
    }
   ],
   "source": [
    "data5=load_images_from_folder('5')\n",
    "\n",
    "for i in range(0,len(data5)):\n",
    "    data5[i]=np.append(data5[i],['5'])\n",
    "data=np.concatenate((data,data5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34789\n"
     ]
    }
   ],
   "source": [
    "data6=load_images_from_folder('6')\n",
    "\n",
    "for i in range(0,len(data6)):\n",
    "    data6[i]=np.append(data6[i],['6'])\n",
    "data=np.concatenate((data,data6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37697\n"
     ]
    }
   ],
   "source": [
    "data7=load_images_from_folder('7')\n",
    "\n",
    "for i in range(0,len(data7)):\n",
    "    data7[i]=np.append(data7[i],['7'])\n",
    "data=np.concatenate((data,data7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40764\n"
     ]
    }
   ],
   "source": [
    "data8=load_images_from_folder('8')\n",
    "\n",
    "for i in range(0,len(data8)):\n",
    "    data8[i]=np.append(data8[i],['8'])\n",
    "data=np.concatenate((data,data8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44500\n"
     ]
    }
   ],
   "source": [
    "data9=load_images_from_folder('9')\n",
    "\n",
    "for i in range(0,len(data9)):\n",
    "    data9[i]=np.append(data9[i],['9'])\n",
    "data=np.concatenate((data,data9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55616\n"
     ]
    }
   ],
   "source": [
    "data0=load_images_from_folder('0')\n",
    "for i in range(0,len(data0)):\n",
    "    data0[i]=np.append(data0[i],['0'])\n",
    "data=np.concatenate((data,data0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48532\n"
     ]
    }
   ],
   "source": [
    "#assign + = 11\n",
    "data11=load_images_from_folder('+')\n",
    "\n",
    "for i in range(0,len(data11)):\n",
    "    data11[i]=np.append(data11[i],['11'])\n",
    "data=np.concatenate((data,data11))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51782\n"
     ]
    }
   ],
   "source": [
    "#assign * = 12\n",
    "data12=load_images_from_folder('times')\n",
    "\n",
    "for i in range(0,len(data12)):\n",
    "    data12[i]=np.append(data12[i],['12'])\n",
    "data=np.concatenate((data,data12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data,index=None)\n",
    "df.to_csv('train_final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('train_final.csv',index_col=False)\n",
    "labels=df_train[['784']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(df_train.columns[[784]],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(321)\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "cat=to_categorical(labels,num_classes=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in range(55616):\n",
    "    l.append(np.array(df_train[i:i+1]).reshape(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.__version__ is 2.1.0\n",
      "tf.keras.__version__ is: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "\n",
    "print(\"tf.__version__ is\", tf.__version__)\n",
    "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
    "\n",
    "def _get_available_gpus():\n",
    "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
    "\n",
    "    # Returns\n",
    "        A list of available GPU devices.\n",
    "    \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "    if tfback._LOCAL_DEVICES is None:\n",
    "        devices = tf.config.list_logical_devices()\n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "\n",
    "tfback._get_available_gpus = _get_available_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(30, (5, 5), input_shape=(1 , 28, 28), activation='relu',data_format = 'channels_first'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(13, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55616/55616 [==============================] - 56s 1ms/step - loss: 1.5411 - accuracy: 0.6075\n",
      "Epoch 2/10\n",
      "55616/55616 [==============================] - 54s 965us/step - loss: 0.3388 - accuracy: 0.9009\n",
      "Epoch 3/10\n",
      "55616/55616 [==============================] - 54s 977us/step - loss: 0.1906 - accuracy: 0.9431\n",
      "Epoch 4/10\n",
      "55616/55616 [==============================] - 54s 964us/step - loss: 0.1322 - accuracy: 0.9610\n",
      "Epoch 5/10\n",
      "55616/55616 [==============================] - 59s 1ms/step - loss: 0.1024 - accuracy: 0.9679\n",
      "Epoch 6/10\n",
      "55616/55616 [==============================] - 58s 1ms/step - loss: 0.0880 - accuracy: 0.9738\n",
      "Epoch 7/10\n",
      "55616/55616 [==============================] - 58s 1ms/step - loss: 0.0685 - accuracy: 0.9799\n",
      "Epoch 8/10\n",
      "55616/55616 [==============================] - 57s 1ms/step - loss: 0.0591 - accuracy: 0.9834\n",
      "Epoch 9/10\n",
      "55616/55616 [==============================] - 57s 1ms/step - loss: 0.0529 - accuracy: 0.9838 2s - loss:\n",
      "Epoch 10/10\n",
      "55616/55616 [==============================] - 57s 1ms/step - loss: 0.0484 - accuracy: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1989d9fee08>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(l), cat, epochs=10, batch_size=200,shuffle=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_final.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
